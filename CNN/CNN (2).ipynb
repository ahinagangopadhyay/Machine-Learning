{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4752624-86f6-4fe4-ad69-3a618842d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61cf4565-880e-4d18-afd8-1859e997d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711c0023-cec5-425e-b427-4fdcaf345b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if k.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badd3fa9-30d6-4377-8665-7ab6b68f8dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba5438d9-eba1-4eb3-ba2c-ba25aac39853",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac14c06-1f92-463f-9555-d93e29e967ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1fa0f36-8dbc-461e-967b-63180abaf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0974892-ac53-43d3-93cf-31d94cc0d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea2a463f-de72-4920-94e4-b28b44ed47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f128a4ba-0f1d-46d5-b53a-393b21a70a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 41ms/step - accuracy: 0.7662 - loss: 0.7108 - val_accuracy: 0.9769 - val_loss: 0.0709\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.9604 - loss: 0.1307 - val_accuracy: 0.9851 - val_loss: 0.0457\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.9709 - loss: 0.0980 - val_accuracy: 0.9868 - val_loss: 0.0396\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.9765 - loss: 0.0797 - val_accuracy: 0.9896 - val_loss: 0.0322\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.9798 - loss: 0.0672 - val_accuracy: 0.9886 - val_loss: 0.0284\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0585 - val_accuracy: 0.9908 - val_loss: 0.0251\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.9822 - loss: 0.0587 - val_accuracy: 0.9906 - val_loss: 0.0255\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.9841 - loss: 0.0519 - val_accuracy: 0.9919 - val_loss: 0.0235\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.9854 - loss: 0.0471 - val_accuracy: 0.9919 - val_loss: 0.0239\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.9865 - loss: 0.0438 - val_accuracy: 0.9927 - val_loss: 0.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2457b69c410>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1a5cbe-6921-4692-a6b0-5239abbb4426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.022314665839076042\n",
      "Test accuracy: 0.9926999807357788\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "model.save(\"mnist_cnn.h5\")\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd15e79-156d-485b-87e7-08fce89c1f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "Predicted digit: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"mnist_cnn.h5\")\n",
    "\n",
    "# Load and preprocess image\n",
    "img = Image.open(\"images.png\").convert('L')  # Convert to grayscale\n",
    "img = ImageOps.invert(img)  # MNIST digits are white on black\n",
    "img = img.resize((28, 28))  # Resize to 28x28\n",
    "\n",
    "# Convert to array and preprocess\n",
    "img_array = np.array(img).astype('float32') / 255.0\n",
    "img_array = img_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(img_array)\n",
    "predicted_digit = np.argmax(prediction)\n",
    "\n",
    "print(\"Predicted digit:\", predicted_digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdedb35e-d6bd-4fd2-b051-1d865c02d8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
