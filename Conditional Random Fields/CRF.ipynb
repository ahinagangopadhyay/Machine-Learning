{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab81453-9d5b-400e-abfc-ffe1f4f8813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite)\n",
      "  Downloading python_crfsuite-0.9.11-cp312-cp312-win_amd64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in c:\\users\\ahina\\appdata\\roaming\\python\\python312\\site-packages (from sklearn-crfsuite) (1.5.1)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in c:\\users\\ahina\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\ahina\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ahina\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ahina\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ahina\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ahina\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahina\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.6)\n",
      "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading python_crfsuite-0.9.11-cp312-cp312-win_amd64.whl (301 kB)\n",
      "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
      "Successfully installed python-crfsuite-0.9.11 sklearn-crfsuite-0.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d1c46e-41dd-480a-b3eb-4107e0278cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3f7800-4036-4b32-9ac0-f143c4488b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\AHINA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "corpus = nltk.corpus.treebank.tagged_sents()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e20e006-ca9a-4864-a0e9-965089a4b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features for each word in a sentence\n",
    "def word_features(sentence, i):\n",
    "    word = sentence[i][0]\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'is_first': i == 0, #if the word is a first word\n",
    "        'is_last': i == len(sentence) - 1,  #if the word is a last word\n",
    "        'is_capitalized': word[0].upper() == word[0],\n",
    "        'is_all_caps': word.upper() == word,      #word is in uppercase\n",
    "        'is_all_lower': word.lower() == word,      #word is in lowercase\n",
    "         #prefix of the word\n",
    "        'prefix-1': word[0],   \n",
    "        'prefix-2': word[:2],\n",
    "        'prefix-3': word[:3],\n",
    "         #suffix of the word\n",
    "        'suffix-1': word[-1],\n",
    "        'suffix-2': word[-2:],\n",
    "        'suffix-3': word[-3:],\n",
    "         #extracting previous word\n",
    "        'prev_word': '' if i == 0 else sentence[i-1][0],\n",
    "         #extracting next word\n",
    "        'next_word': '' if i == len(sentence)-1 else sentence[i+1][0],\n",
    "        'has_hyphen': '-' in word,    #if word has hypen\n",
    "        'is_numeric': word.isdigit(),  #if word is in numeric\n",
    "        'capitals_inside': word[1:].lower() != word[1:]\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ec68d-f7f6-4f6b-a546-15383a79649b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a19cba-2ae5-4724-9684-58b4e0dabda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for each sentence in the corpus\n",
    "X = []\n",
    "y = []\n",
    "for sentence in corpus:\n",
    "    X_sentence = []\n",
    "    y_sentence = []\n",
    "    for i in range(len(sentence)):\n",
    "        X_sentence.append(word_features(sentence, i))\n",
    "        y_sentence.append(sentence[i][1])\n",
    "    X.append(X_sentence)\n",
    "    y.append(y_sentence)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcae3c02-1dc1-4989-90fd-0d381ed56c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9632716203403363\n"
     ]
    }
   ],
   "source": [
    "# Train a CRF model on the training data\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data and evaluate the performance\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf0b4a2-4c54-4baf-9de2-2a39dbeeb55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ahina', 'NNP'), ('is', 'VBZ'), ('testing', 'NN'), ('CRF', 'NNP'), ('model', 'NN'), ('for', 'IN'), ('POS', 'NNP'), ('tagging', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "\n",
    "# 1. Feature extraction function for each word\n",
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        prev_word = sent[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': prev_word.lower(),\n",
    "            '-1:word.istitle()': prev_word.istitle(),\n",
    "            '-1:word.isupper()': prev_word.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True  # Beginning of sentence\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        next_word = sent[i+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': next_word.lower(),\n",
    "            '+1:word.istitle()': next_word.istitle(),\n",
    "            '+1:word.isupper()': next_word.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "# Convert sentence to features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "train_sents = [\n",
    "    ([\"Ahina\", \"is\", \"trying\", \"out\", \"CRF\", \"algorithm\", \"for\", \"Natural\", \"Language\", \"Processing\", \"POS\", \"Tagging\", \".\"],\n",
    "     [\"NNP\", \"VBZ\", \"VBG\", \"RP\", \"NNP\", \"NN\", \"IN\", \"NNP\", \"NNP\", \"NNP\", \"NNP\", \"NN\", \".\"]),\n",
    "\n",
    "    ([\"The\", \"CRF\", \"model\", \"performs\", \"well\", \"on\", \"sequence\", \"labeling\", \"tasks\", \".\"],\n",
    "     [\"DT\", \"NNP\", \"NN\", \"VBZ\", \"RB\", \"IN\", \"NN\", \"NN\", \"NNS\", \".\"]),\n",
    "\n",
    "    ([\"She\", \"loves\", \"to\", \"learn\", \"about\", \"machine\", \"learning\", \"and\", \"natural\", \"language\", \"processing\", \".\"],\n",
    "     [\"PRP\", \"VBZ\", \"TO\", \"VB\", \"IN\", \"NN\", \"NN\", \"CC\", \"JJ\", \"NN\", \"NN\", \".\"]),\n",
    "\n",
    "    ([\"Python\", \"is\", \"a\", \"popular\", \"programming\", \"language\", \"for\", \"data\", \"science\", \".\"],\n",
    "     [\"NNP\", \"VBZ\", \"DT\", \"JJ\", \"NN\", \"NN\", \"IN\", \"NN\", \"NN\", \".\"]),\n",
    "\n",
    "    ([\"We\", \"can\", \"build\", \"custom\", \"POS\", \"taggers\", \"using\", \"CRF\", \"models\", \".\"],\n",
    "     [\"PRP\", \"MD\", \"VB\", \"JJ\", \"NNP\", \"NNS\", \"VBG\", \"NNP\", \"NNS\", \".\"]),\n",
    "\n",
    "    ([\"Natural\", \"language\", \"processing\", \"involves\", \"many\", \"complex\", \"tasks\", \".\"],\n",
    "     [\"JJ\", \"NN\", \"NN\", \"VBZ\", \"DT\", \"JJ\", \"NNS\", \".\"]),\n",
    "\n",
    "    ([\"Machine\", \"learning\", \"algorithms\", \"can\", \"improve\", \"text\", \"classification\", \".\"],\n",
    "     [\"NNP\", \"NN\", \"NNS\", \"MD\", \"VB\", \"NN\", \"NN\", \".\"]),\n",
    "\n",
    "    ([\"The\", \"researcher\", \"analyzed\", \"the\", \"results\", \"carefully\", \".\"],\n",
    "     [\"DT\", \"NN\", \"VBD\", \"DT\", \"NNS\", \"RB\", \".\"])\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Prepare training data in CRF input format\n",
    "X_train = [sent2features(s) for s, _ in train_sents]\n",
    "y_train = [tags for _, tags in train_sents]\n",
    "\n",
    "# 2. Train the CRF model\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,  # L1 regularization\n",
    "    'c2': 1e-3, # L2 regularization\n",
    "    'max_iterations': 100,\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "trainer.train('pos_model.crfsuite')\n",
    "\n",
    "# 3. Load the trained model to tag new sentences\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('pos_model.crfsuite')\n",
    "\n",
    "test_sentence = \"Ahina is testing CRF model for POS tagging .\".split()\n",
    "X_test = sent2features(test_sentence)\n",
    "predicted_tags = tagger.tag(X_test)\n",
    "\n",
    "print(list(zip(test_sentence, predicted_tags)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d813b7-5cb5-4474-b6a5-02a75d9c796d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
