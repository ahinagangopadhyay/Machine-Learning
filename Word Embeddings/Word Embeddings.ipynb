{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34f695d2-39c2-46e6-a31b-06a0e61366f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\AHINA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 2000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "\n",
    "# Download corpus\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "# Load and tokenize documents\n",
    "documents = [\n",
    "    list(movie_reviews.words(fileid))\n",
    "    for fileid in movie_reviews.fileids()\n",
    "]\n",
    "\n",
    "# Shuffle words within each doc to prevent overfitting to order\n",
    "random.shuffle(documents)\n",
    "\n",
    "# Print sample\n",
    "print(f\"Number of reviews: {len(documents)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d1d0638-5125-4b2d-91c6-7950af4c1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec on movie reviews\n",
    "model = Word2Vec(\n",
    "    sentences=documents,\n",
    "    vector_size=100,    # 100-dimensional embeddings\n",
    "    window=5,           # Context window\n",
    "    min_count=2,        # Ignore rare words\n",
    "    workers=4,          # Parallel threads\n",
    "    sg=1                # Skip-gram (1) or CBOW (0)\n",
    ")\n",
    "\n",
    "# Save model if needed\n",
    "# model.save(\"movie_reviews_word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd584e32-f4e2-49f2-a7c6-5ca79a414286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sidney', 0.6609278321266174), ('queen', 0.6380879878997803), ('jane', 0.6356750726699829), ('neve', 0.6116956472396851), ('roman', 0.6087451577186584), ('bud', 0.6077442169189453), ('ricci', 0.6057746410369873), ('rachel', 0.6050881147384644), ('linda', 0.6034192442893982), ('manager', 0.6031489968299866)]\n"
     ]
    }
   ],
   "source": [
    "result = model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])\n",
    "print(result)  # Should return something like \"queen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34fdd051-2ffd-4de7-ae90-67cf550c58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words similar to 'good':\n",
      "great: 0.75\n",
      "decent: 0.74\n",
      "bad: 0.70\n",
      "passable: 0.68\n",
      "terrible: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Most similar to 'good'\n",
    "print(\"\\nWords similar to 'good':\")\n",
    "for word, sim in model.wv.most_similar('good', topn=5):\n",
    "    print(f\"{word}: {sim:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d5ca551-2c5a-4cd9-8035-1e4c0eba7808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector for 'king':\n",
      "[ 0.03656607  0.02534573  0.03378296  0.00381261  0.03175386 -0.01702927\n",
      " -0.00473246  0.02884854 -0.03760872 -0.01968175 -0.03755583 -0.00465655\n",
      "  0.04769655 -0.03658936 -0.01167611 -0.00968685  0.04039469 -0.02966029\n",
      "  0.00022053 -0.02377453]\n",
      "\n",
      "Words similar to 'king':\n",
      "her: 0.46\n",
      "house: 0.45\n",
      "paris: 0.44\n",
      "dog: 0.40\n",
      "crown: 0.40\n",
      "\n",
      "Analogy: 'king' - 'man' + 'queen' ≈ ?\n",
      "Result: palace (0.57)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# List of stop words to remove (articles, prepositions, verbs)\n",
    "stop_words = set([\n",
    "    \"a\", \"an\", \"the\", \"is\", \"are\", \"was\", \"were\", \"in\", \"on\", \"and\", \"of\", \"to\", \"with\", \"for\", \n",
    "    \"has\", \"have\", \"had\", \"be\", \"as\", \"by\", \"at\", \"from\", \"that\", \"this\", \"it\", \"he\", \"she\", \"they\",\n",
    "    \"you\", \"i\", \"we\", \"but\", \"or\", \"not\", \"so\", \"if\", \"then\", \"when\", \"which\", \"who\", \"whom\",\n",
    "    \"rules\", \"rides\", \"drives\", \"live\", \"married\"\n",
    "])\n",
    "\n",
    "# Expanded corpus with more sentences\n",
    "sentences = [\n",
    "    [\"king\", \"rules\", \"a\", \"kingdom\"],\n",
    "    [\"queen\", \"rules\", \"a\", \"kingdom\", \"with\", \"wisdom\"],\n",
    "    [\"queen\", \"is\", \"a\", \"woman\"],\n",
    "    [\"man\", \"is\", \"strong\"],\n",
    "    [\"woman\", \"is\", \"wise\"],\n",
    "    [\"prince\", \"is\", \"the\", \"son\", \"of\", \"a\", \"king\"],\n",
    "    [\"princess\", \"is\", \"the\", \"daughter\", \"of\", \"a\", \"queen\"],\n",
    "    [\"the\", \"king\", \"and\", \"queen\", \"live\", \"in\", \"a\", \"palace\"],\n",
    "    [\"the\", \"queen\", \"is\", \"married\", \"to\", \"the\", \"king\"],\n",
    "    [\"the\", \"man\", \"drives\", \"a\", \"car\"],\n",
    "    [\"the\", \"woman\", \"rides\", \"a\", \"bicycle\"],\n",
    "    [\"dogs\", \"are\", \"loyal\", \"animals\"],\n",
    "    [\"cats\", \"are\", \"independent\", \"animals\"],\n",
    "    [\"paris\", \"is\", \"the\", \"capital\", \"of\", \"france\"],\n",
    "    [\"london\", \"is\", \"the\", \"capital\", \"of\", \"england\"],\n",
    "    [\"apple\", \"is\", \"a\", \"fruit\"],\n",
    "    [\"carrot\", \"is\", \"a\", \"vegetable\"],\n",
    "    [\"python\", \"is\", \"a\", \"programming\", \"language\"],\n",
    "    [\"java\", \"is\", \"a\", \"programming\", \"language\"],\n",
    "    [\"dog\", \"barks\", \"loudly\"],\n",
    "    [\"cat\", \"sleeps\", \"all\", \"day\"],\n",
    "    [\"prince\", \"wears\", \"a\", \"crown\"],\n",
    "    [\"princess\", \"wears\", \"a\", \"tiara\"],\n",
    "    [\"kingdom\", \"has\", \"many\", \"subjects\"],\n",
    "    [\"queen\", \"loves\", \"her\", \"people\"],\n",
    "    [\"man\", \"builds\", \"a\", \"house\"],\n",
    "    [\"woman\", \"plants\", \"a\", \"garden\"],\n",
    "    [\"children\", \"play\", \"in\", \"the\", \"park\"],\n",
    "]\n",
    "\n",
    "# Remove stop words from each sentence\n",
    "filtered_sentences = [\n",
    "    [word for word in sentence if word not in stop_words]\n",
    "    for sentence in sentences\n",
    "]\n",
    "\n",
    "# Train Word2Vec model on filtered sentences\n",
    "model = Word2Vec(filtered_sentences, vector_size=20, window=3, min_count=1, workers=2, sg=1)\n",
    "\n",
    "# Show vector for 'king'\n",
    "print(\"Word vector for 'king':\")\n",
    "print(model.wv['king'])\n",
    "\n",
    "# Similar words to 'king'\n",
    "print(\"\\nWords similar to 'king':\")\n",
    "for word, sim in model.wv.most_similar('king', topn=5):\n",
    "    print(f\"{word}: {sim:.2f}\")\n",
    "\n",
    "# Word analogy: king - man + woman = ?\n",
    "print(\"\\nAnalogy: 'king' - 'man' + 'queen' ≈ ?\")\n",
    "result = model.wv.most_similar(positive=['king', 'queen'], negative=['man'], topn=1)\n",
    "print(f\"Result: {result[0][0]} ({result[0][1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc428974-c7fe-4898-9137-f9cc5f3b34b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
